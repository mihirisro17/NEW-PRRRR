from flask import Flask, render_template, jsonify, request
import requests
from datetime import datetime, timedelta
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import json
import os

app = Flask(__name__, 
            static_url_path='/geoentity_monitoring/static',
            static_folder='static',
            template_folder='templates')

BASE_URL = "https://vedas.sac.gov.in/geoentity-services/api"
RESULTS_FILE = "filter_check_results.json"

class APIMonitor:
    def __init__(self):
        self.results = {
            'sources': {},
            'geoentities': {},
            'last_check': None
        }
        self.filter_check_results = self.load_results()
        self.filter_check_status = {
            'running': False,
            'progress': 0,
            'total': 0,
            'current_source': None,
            'current_entity': None,
            'completed_sources': 0,
            'total_sources': 0
        }
        self.last_daily_check = self.get_last_daily_check()
        
        # Start daily check thread
        self.start_daily_check_thread()
    
    def load_results(self):
        """Load saved filter check results"""
        if os.path.exists(RESULTS_FILE):
            try:
                with open(RESULTS_FILE, 'r') as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def save_results(self):
        """Save filter check results to file"""
        try:
            with open(RESULTS_FILE, 'w') as f:
                json.dump(self.filter_check_results, f, indent=2)
        except Exception as e:
            print(f"Error saving results: {e}")
    
    def get_last_daily_check(self):
        """Get last daily check timestamp"""
        if os.path.exists('last_daily_check.txt'):
            try:
                with open('last_daily_check.txt', 'r') as f:
                    return datetime.fromisoformat(f.read().strip())
            except:
                return None
        return None
    
    def save_last_daily_check(self):
        """Save last daily check timestamp"""
        try:
            with open('last_daily_check.txt', 'w') as f:
                f.write(datetime.now().isoformat())
        except Exception as e:
            print(f"Error saving timestamp: {e}")
    
    def start_daily_check_thread(self):
        """Start background thread for daily checks"""
        def daily_check_worker():
            while True:
                try:
                    now = datetime.now()
                    
                    # Check if we need to run (once per day)
                    if self.last_daily_check is None or (now - self.last_daily_check) > timedelta(days=1):
                        print(f"Starting daily filter check at {now}")
                        self.run_all_filter_checks()
                        self.last_daily_check = now
                        self.save_last_daily_check()
                        print(f"Daily filter check completed at {datetime.now()}")
                    
                    # Sleep for 1 hour then check again
                    time.sleep(3600)
                except Exception as e:
                    print(f"Error in daily check: {e}")
                    time.sleep(3600)
        
        thread = threading.Thread(target=daily_check_worker, daemon=True)
        thread.start()
        print("Daily check thread started")
    
    def check_sources_api(self):
        """Check the geoentity sources API"""
        url = f"{BASE_URL}/geoentity-sources/"
        start_time = time.time()
        
        try:
            response = requests.get(url, timeout=10)
            response_time = round((time.time() - start_time) * 1000, 2)
            
            return {
                'status': 'success' if response.status_code == 200 else 'error',
                'status_code': response.status_code,
                'response_time': response_time,
                'data': response.json() if response.status_code == 200 else None,
                'error': None,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        except Exception as e:
            return {
                'status': 'error',
                'status_code': None,
                'response_time': round((time.time() - start_time) * 1000, 2),
                'data': None,
                'error': str(e),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def check_geoentity_api(self, source_id, source_name, category, project):
        """Check individual geoentity API"""
        url = f"{BASE_URL}/geoentity-sources/{source_id}/geoentities"
        start_time = time.time()
        
        try:
            response = requests.get(url, timeout=10)
            response_time = round((time.time() - start_time) * 1000, 2)
            
            return {
                'id': source_id,
                'name': source_name,
                'category': category,
                'project': project,
                'status': 'success' if response.status_code == 200 else 'error',
                'status_code': response.status_code,
                'response_time': response_time,
                'count': response.json().get('count', 0) if response.status_code == 200 else 0,
                'error': None,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'url': url
            }
        except Exception as e:
            return {
                'id': source_id,
                'name': source_name,
                'category': category,
                'project': project,
                'status': 'error',
                'status_code': None,
                'response_time': round((time.time() - start_time) * 1000, 2),
                'count': 0,
                'error': str(e),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'url': url
            }
    
    def run_full_check(self):
        """Run complete monitoring check"""
        sources_result = self.check_sources_api()
        self.results['sources'] = sources_result
        
        if sources_result['status'] == 'success' and sources_result['data']:
            sources = sources_result['data'].get('data', [])
            
            geoentity_results = []
            with ThreadPoolExecutor(max_workers=10) as executor:
                futures = {
                    executor.submit(
                        self.check_geoentity_api, 
                        source['id'], 
                        source['name'],
                        source.get('category', 'N/A'),
                        source.get('project', 'N/A')
                    ): source for source in sources
                }
                
                for future in as_completed(futures):
                    try:
                        result = future.result()
                        geoentity_results.append(result)
                    except Exception as e:
                        source = futures[future]
                        geoentity_results.append({
                            'id': source['id'],
                            'name': source['name'],
                            'category': source.get('category', 'N/A'),
                            'project': source.get('project', 'N/A'),
                            'status': 'error',
                            'error': str(e)
                        })
            
            self.results['geoentities'] = sorted(geoentity_results, key=lambda x: x['id'])
        
        self.results['last_check'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        return self.results
    
    def check_geoentity_with_prefix(self, source_id, geoentity_id):
        """Check geoentity with prefix parameter"""
        url = f"{BASE_URL}/geoentity-sources/{source_id}/geoentities?prefix={geoentity_id}"
        start_time = time.time()
        
        try:
            response = requests.get(url, timeout=10)
            response_time = round((time.time() - start_time) * 1000, 2)
            
            return {
                'source_id': source_id,
                'geoentity_id': geoentity_id,
                'status': 'success' if response.status_code == 200 else 'error',
                'status_code': response.status_code,
                'response_time': response_time,
                'count': response.json().get('count', 0) if response.status_code == 200 else 0,
                'url': url,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        except Exception as e:
            return {
                'source_id': source_id,
                'geoentity_id': geoentity_id,
                'status': 'error',
                'error': str(e),
                'response_time': round((time.time() - start_time) * 1000, 2),
                'url': url,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def check_geoentity_with_bbox(self, source_id, bbox="72.450,22.880,72.700,23.125"):
        """Check geoentity with bbox parameter"""
        url = f"{BASE_URL}/geoentity-sources/{source_id}/geoentities?bbox={bbox}&parents=1"
        start_time = time.time()
        
        try:
            response = requests.get(url, timeout=10)
            response_time = round((time.time() - start_time) * 1000, 2)
            
            return {
                'source_id': source_id,
                'bbox': bbox,
                'status': 'success' if response.status_code == 200 else 'error',
                'status_code': response.status_code,
                'response_time': response_time,
                'count': response.json().get('count', 0) if response.status_code == 200 else 0,
                'url': url,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        except Exception as e:
            return {
                'source_id': source_id,
                'bbox': bbox,
                'status': 'error',
                'error': str(e),
                'response_time': round((time.time() - start_time) * 1000, 2),
                'url': url,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def run_single_filter_check(self, source_id):
        """Run filter check for a single source"""
        source_key = f"source_{source_id}"
        self.filter_check_results[source_key] = {
            'source_id': source_id,
            'started_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'running',
            'checks': []
        }
        
        try:
            # Special handling for IDs 15, 26, 28 - use bbox
            if source_id in [15, 26, 28]:
                self.filter_check_status['current_source'] = f"Source {source_id} (bbox check)"
                result = self.check_geoentity_with_bbox(source_id)
                self.filter_check_results[source_key]['checks'].append(result)
                self.filter_check_results[source_key]['type'] = 'bbox'
            else:
                # Get all geoentities first
                url = f"{BASE_URL}/geoentity-sources/{source_id}/geoentities"
                response = requests.get(url, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    geoentities = data.get('data', [])
                    total = len(geoentities)
                    
                    self.filter_check_status['total'] = total
                    self.filter_check_results[source_key]['type'] = 'prefix'
                    self.filter_check_results[source_key]['total_entities'] = total
                    
                    # Check each geoentity with prefix
                    for idx, entity in enumerate(geoentities):
                        geoentity_id = entity.get('geoentity_id')
                        self.filter_check_status['current_entity'] = geoentity_id
                        self.filter_check_status['progress'] = idx + 1
                        
                        result = self.check_geoentity_with_prefix(source_id, geoentity_id)
                        result['entity_name'] = entity.get('name', 'N/A')
                        result['parent_name'] = entity.get('parent_name', 'N/A')
                        
                        self.filter_check_results[source_key]['checks'].append(result)
                        time.sleep(0.05)  # Small delay
            
            self.filter_check_results[source_key]['status'] = 'completed'
            self.filter_check_results[source_key]['completed_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
        except Exception as e:
            self.filter_check_results[source_key]['status'] = 'error'
            self.filter_check_results[source_key]['error'] = str(e)
        
        # Save results after each source
        self.save_results()
    
    def run_all_filter_checks(self):
        """Run filter checks for all sources"""
        if self.filter_check_status['running']:
            return {'error': 'A filter check is already running'}
        
        self.filter_check_status['running'] = True
        self.filter_check_status['progress'] = 0
        
        try:
            # Get all sources
            sources_result = self.check_sources_api()
            
            if sources_result['status'] == 'success' and sources_result['data']:
                sources = sources_result['data'].get('data', [])
                total_sources = len(sources)
                
                self.filter_check_status['total_sources'] = total_sources
                self.filter_check_status['completed_sources'] = 0
                
                # Run check for each source
                for idx, source in enumerate(sources):
                    source_id = source['id']
                    self.filter_check_status['current_source'] = f"Source {source_id}: {source['name']}"
                    self.filter_check_status['completed_sources'] = idx
                    
                    print(f"Checking source {source_id} ({idx+1}/{total_sources})")
                    self.run_single_filter_check(source_id)
                
                self.filter_check_status['completed_sources'] = total_sources
                print(f"All filter checks completed!")
                
        except Exception as e:
            print(f"Error in run_all_filter_checks: {e}")
        
        finally:
            self.filter_check_status['running'] = False
            self.filter_check_status['progress'] = 0
            self.filter_check_status['current_source'] = None
            self.filter_check_status['current_entity'] = None

monitor = APIMonitor()

@app.route('/geoentity_monitoring/')
def index():
    return render_template('dashboard.html')

@app.route('/geoentity_monitoring/api/check', methods=['GET'])
def check_apis():
    results = monitor.run_full_check()
    return jsonify(results)

@app.route('/geoentity_monitoring/api/stats', methods=['GET'])
def get_stats():
    if not monitor.results.get('geoentities'):
        return jsonify({'error': 'No data available'})
    
    geoentities = monitor.results['geoentities']
    total = len(geoentities)
    success = sum(1 for g in geoentities if g['status'] == 'success')
    failed = total - success
    avg_response = sum(g['response_time'] for g in geoentities) / total if total > 0 else 0
    
    return jsonify({
        'total_endpoints': total,
        'success': success,
        'failed': failed,
        'success_rate': round((success / total * 100), 2) if total > 0 else 0,
        'avg_response_time': round(avg_response, 2)
    })

@app.route('/geoentity_monitoring/api/filter-check/start/<int:source_id>', methods=['POST'])
def start_filter_check(source_id):
    """Start detailed filter check for a source"""
    if monitor.filter_check_status['running']:
        return jsonify({'error': 'A filter check is already running'}), 400
    
    # Run in background thread
    def run_single():
        monitor.filter_check_status['running'] = True
        monitor.run_single_filter_check(source_id)
        monitor.filter_check_status['running'] = False
    
    thread = threading.Thread(target=run_single, daemon=True)
    thread.start()
    
    return jsonify({
        'status': 'started',
        'source_id': source_id,
        'message': 'Filter check started in background'
    })

@app.route('/geoentity_monitoring/api/filter-check/start-all', methods=['POST'])
def start_all_filter_checks():
    """Start filter check for all sources"""
    if monitor.filter_check_status['running']:
        return jsonify({'error': 'A filter check is already running'}), 400
    
    # Run in background thread
    thread = threading.Thread(target=monitor.run_all_filter_checks, daemon=True)
    thread.start()
    
    return jsonify({
        'status': 'started',
        'message': 'Filter check started for all sources'
    })

@app.route('/geoentity_monitoring/api/filter-check/status', methods=['GET'])
def get_filter_check_status():
    """Get status of current filter check"""
    status = monitor.filter_check_status.copy()
    status['last_daily_check'] = monitor.last_daily_check.strftime('%Y-%m-%d %H:%M:%S') if monitor.last_daily_check else 'Never'
    return jsonify(status)

@app.route('/geoentity_monitoring/api/filter-check/results/<int:source_id>', methods=['GET'])
def get_filter_check_results(source_id):
    """Get results of filter check for a source"""
    source_key = f"source_{source_id}"
    
    if source_key in monitor.filter_check_results:
        return jsonify(monitor.filter_check_results[source_key])
    else:
        return jsonify({'error': 'No results found for this source'}), 404

@app.route('/geoentity_monitoring/api/filter-check/all-results', methods=['GET'])
def get_all_filter_results():
    """Get all filter check results"""
    return jsonify(monitor.filter_check_results)

if __name__ == '__main__':
    print("=" * 60)
    print("GeoEntity Monitoring Server Starting...")
    print("=" * 60)
    print(f"Server: http://127.0.0.1:1115/geoentity_monitoring/")
    print(f"Daily auto-check: Enabled")
    if monitor.last_daily_check:
        print(f"Last daily check: {monitor.last_daily_check.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print(f"Last daily check: Never (will run soon)")
    print("=" * 60)
    app.run(debug=True, host='0.0.0.0', port=1115)









<div class="section-header" style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap;">
    <div>
        <h2>üîç Detailed Filter Checking</h2>
        <p style="color: #718096; font-size: 14px; margin-top: 8px;">
            Check each geoentity with prefix parameter or bbox for specific sources
        </p>
        <p style="color: #718096; font-size: 13px; margin-top: 4px;" id="lastDailyCheck">
            Last auto-check: Loading...
        </p>
    </div>
    <button class="btn btn-primary" onclick="runAllFilterChecks()" id="runAllBtn">
        <span>üöÄ</span> Run All Sources
    </button>
</div>








// Add this after startFilterCheck function
async function runAllFilterChecks() {
    if (confirm('This will check all sources with their geoentities. This may take 10-30 minutes. Continue?')) {
        try {
            document.getElementById('loadingOverlay').classList.add('active');
            document.getElementById('runAllBtn').disabled = true;
            
            const response = await fetch('/geoentity_monitoring/api/filter-check/start-all', {
                method: 'POST'
            });
            
            const data = await response.json();
            
            if (data.status === 'started') {
                // Switch to filter tab
                document.querySelectorAll('.tab-btn')[1].click();
                
                // Show status box
                document.getElementById('filterCheckStatus').style.display = 'block';
                document.getElementById('filterCheckBadge').style.display = 'inline';
                
                // Start polling for status
                startFilterCheckPolling(null);
            } else {
                alert('Error: ' + data.error);
                document.getElementById('runAllBtn').disabled = false;
            }
        } catch (error) {
            console.error('Error:', error);
            alert('Failed to start filter check');
            document.getElementById('runAllBtn').disabled = false;
        } finally {
            document.getElementById('loadingOverlay').classList.remove('active');
        }
    }
}






async function updateFilterCheckStatus(sourceId) {
    try {
        const response = await fetch('/geoentity_monitoring/api/filter-check/status');
        const status = await response.json();
        
        // Update last daily check info
        if (status.last_daily_check) {
            document.getElementById('lastDailyCheck').textContent = 
                'Last auto-check: ' + status.last_daily_check;
        }
        
        if (status.running) {
            // Check if it's all sources or single source
            if (status.total_sources > 0) {
                // Multiple sources
                var progressPercent = status.total_sources > 0 ? 
                    (status.completed_sources / status.total_sources * 100) : 0;
                
                document.getElementById('filterStatusText').textContent = 
                    'Checking all sources: ' + (status.current_source || 'Initializing...');
                document.getElementById('filterProgress').textContent = 
                    status.completed_sources + '/' + status.total_sources + ' sources';
                document.getElementById('filterProgressBar').style.width = progressPercent + '%';
                document.getElementById('currentCheckInfo').textContent = 
                    'Current entity: ' + (status.current_entity || 'Please wait...');
            } else {
                // Single source
                var progressPercent = status.total > 0 ? (status.progress / status.total * 100) : 0;
                
                document.getElementById('filterStatusText').textContent = 
                    'Checking: ' + (status.current_source || 'Initializing...');
                document.getElementById('filterProgress').textContent = 
                    status.progress + '/' + status.total;
                document.getElementById('filterProgressBar').style.width = progressPercent + '%';
                document.getElementById('currentCheckInfo').textContent = 
                    'Current: ' + (status.current_entity || 'Please wait...');
            }
        } else {
            // Check completed
            clearInterval(filterCheckInterval);
            filterCheckInterval = null;
            
            document.getElementById('filterCheckStatus').style.display = 'none';
            document.getElementById('filterCheckBadge').style.display = 'none';
            document.getElementById('runAllBtn').disabled = false;
            
            // Load all results
            loadAllFilterResults();
        }
    } catch (error) {
        console.error('Error polling status:', error);
    }
}




