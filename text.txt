import sys
sys.path.append("/opt/vedas_env/lib/raster_data_system")
sys.path.append("/opt/vedas_env/script/raster_data_system")

import vedas_raster_lib.data as data
import numpy as np
import datetime

from datetime import datetime, timedelta
import json
import rasterio
from rasterio.transform import rowcol
from rasterio import features

from shapely.geometry import shape as shapely_shape, Point, mapping
from shapely.geometry import shape
from scipy import ndimage
from scipy.ndimage import label


def save_diff_tiff(diff_array, mask, transform, crs, out_path):
    """Save difference raster with masked changes"""
    output = np.zeros_like(diff_array, dtype='float32')
    output[mask] = diff_array[mask]
    output[~mask] = np.nan

    with rasterio.open(
        out_path, 'w', driver='GTiff',
        height=output.shape[0], width=output.shape[1],
        count=1, dtype=output.dtype, crs=crs,
        transform=transform, nodata=np.nan, compress='lzw'
    ) as dst:
        dst.write(output, 1)
    
    print(f"Saved change detection: {out_path}")


def save_array_as_tiff(array, transform, crs, out_path, description=""):
    """Save a single numpy array as GeoTIFF"""
    with rasterio.open(
        out_path, 'w', driver='GTiff',
        height=array.shape[0], width=array.shape[1],
        count=1, dtype=array.dtype, crs=crs,
        transform=transform, compress='lzw'
    ) as dst:
        dst.write(array, 1)
    
    print(f"Saved {description}: {out_path}")


def save_cluster_polygons_tiff(labeled_array, transform, crs, out_path):
    """
    Save cluster polygons as raster TIF
    Each cluster has its ID as pixel value
    """
    output = labeled_array.astype('int32')
    
    with rasterio.open(
        out_path, 'w', driver='GTiff',
        height=output.shape[0], width=output.shape[1],
        count=1, dtype=output.dtype, crs=crs,
        transform=transform, nodata=0, compress='lzw'
    ) as dst:
        dst.write(output, 1)
    
    print(f"Saved cluster polygons: {out_path}")


def save_cluster_points_tiff(clustered_features, transform, crs, shape, out_path, marker_radius_pixels=5):
    """Save cluster center points as GeoTIFF with visible markers"""
    output = np.zeros(shape, dtype='float32')
    
    for feature in clustered_features:
        # Get center point from polygon
        geom = shapely_shape(feature['geometry'])
        center = geom.centroid
        lon, lat = center.x, center.y
        
        try:
            row, col = rowcol(transform, lon, lat)
            
            if 0 <= row < shape[0] and 0 <= col < shape[1]:
                value = abs(feature['properties'].get('mean_difference', 100))
                
                # Draw circle
                for dr in range(-marker_radius_pixels, marker_radius_pixels + 1):
                    for dc in range(-marker_radius_pixels, marker_radius_pixels + 1):
                        if dr*dr + dc*dc <= marker_radius_pixels*marker_radius_pixels:
                            r, c = row + dr, col + dc
                            if 0 <= r < shape[0] and 0 <= c < shape[1]:
                                output[r, c] = value
        except:
            continue
    
    with rasterio.open(
        out_path, 'w', driver='GTiff',
        height=shape[0], width=shape[1],
        count=1, dtype=output.dtype, crs=crs,
        transform=transform, nodata=0, compress='lzw'
    ) as dst:
        dst.write(output, 1)
    
    print(f"Saved cluster points: {out_path}")


def cluster_connected_pixels_polygons(mask, diff_array, arr1, arr2, transform, crs, polygon_geom=None):
    """
    Cluster pixels using connected component labeling
    Returns polygons instead of points
    """
    structure = ndimage.generate_binary_structure(2, 2)  # 8-connectivity
    labeled_array, num_clusters = label(mask, structure=structure)
    
    print(f"Found {num_clusters} connected pixel clusters")
    
    cluster_polygons = []
    
    # Convert raster clusters to vector polygons
    for geom, value in features.shapes(labeled_array.astype('int32'), transform=transform):
        cluster_id = int(value)
        
        if cluster_id == 0:  # Skip background
            continue
        
        # Create shapely polygon
        polygon = shapely_shape(geom)
        
        # Filter by input polygon if provided
        if polygon_geom is not None:
            if not polygon.intersects(polygon_geom):
                continue
            # Clip to input polygon
            polygon = polygon.intersection(polygon_geom)
            if polygon.is_empty:
                continue
        
        # Get cluster mask for statistics
        cluster_mask = labeled_array == cluster_id
        
        # Get all pixel positions
        cluster_positions = np.argwhere(cluster_mask)
        
        # Get difference values
        cluster_diff_values = diff_array[cluster_mask]
        
        # Find pixel with maximum deforestation
        max_deforest_idx = np.argmin(cluster_diff_values)
        center_row, center_col = cluster_positions[max_deforest_idx]
        
        # Calculate cluster statistics
        cluster_arr1_values = arr1[cluster_mask]
        cluster_arr2_values = arr2[cluster_mask]
        
        num_pixels = np.sum(cluster_mask)
        mean_diff = float(np.mean(cluster_diff_values))
        mean_current = float(np.mean(cluster_arr1_values))
        mean_previous = float(np.mean(cluster_arr2_values))
        
        # Get pixel values at most deforested location
        pixel_diff = float(diff_array[center_row, center_col])
        pixel_current = float(arr1[center_row, center_col])
        pixel_previous = float(arr2[center_row, center_col])
        
        # Calculate area in square meters (approximate)
        area_pixels = polygon.area  # In pixel units squared
        pixel_area_m2 = abs(transform.a * transform.e)  # Pixel area in map units
        area_m2 = area_pixels * pixel_area_m2
        
        cluster_polygons.append({
            "type": "Feature",
            "geometry": mapping(polygon),  # Polygon geometry instead of Point
            "properties": {
                "cluster_id": cluster_id,
                "num_points": int(num_pixels),
                "area_m2": float(area_m2),
                "mean_difference": mean_diff,
                "mean_current_value": mean_current,
                "mean_previous_value": mean_previous,
                "max_deforest_difference": pixel_diff,
                "max_deforest_current": pixel_current,
                "max_deforest_previous": pixel_previous,
                "max_deforest_row": int(center_row),
                "max_deforest_col": int(center_col)
            }
        })
    
    print(f"Returning {len(cluster_polygons)} cluster polygons")
    return cluster_polygons, labeled_array


def extract_bbox_from_geojson(geojson_str):
    """Extract bounding boxes and geometries from GeoJSON"""
    geojson_data = json.loads(geojson_str)
    bboxes = []

    if geojson_data['type'] == 'FeatureCollection':
        for feature in geojson_data['features']:
            geom = shape(feature['geometry'])
            bounds = geom.bounds
            bbox = (bounds[0], bounds[1], bounds[2], bounds[3])
            bboxes.append((bbox, geom, feature))

    return bboxes


def build_time_string(args):
    """Build time strings for current and previous year"""
    def date_str(year, mmdd):
        return f"{year}{mmdd}000000"

    now = datetime.now()
    fmt = "%Y%m%d%H%M%S"
    t1_from, t1_to, t2_from, t2_to = (None, None, None, None)

    if "from_mmdd" in args and "to_mmdd" in args and "from_year" not in args and "to_year" not in args:
        current_year = now.year
        prev_year = current_year - 1
        t1_from = date_str(current_year, args["from_mmdd"])
        t1_to = date_str(current_year, args["to_mmdd"])
        t2_from = date_str(prev_year, args["from_mmdd"])
        t2_to = date_str(prev_year, args["to_mmdd"])
    
    elif "from_mmdd" in args and "to_mmdd" in args and "from_year" in args and "to_year" in args:
        t1_from = date_str(args["from_year"], args["from_mmdd"])
        t1_to = date_str(args["to_year"], args["to_mmdd"])
        t2_from = date_str(str(int(args["from_year"])-1), args["from_mmdd"])
        t2_to = date_str(str(int(args["to_year"])-1), args["to_mmdd"])
        
    elif "from_mmdd" not in args and "to_mmdd" not in args and "from_year" in args and "to_year" in args:
        current_mmdd = now.strftime("%m%d")
        t1_to_str = f"{args['to_year']}{current_mmdd}000000"
        t1_to_date = datetime.strptime(t1_to_str, fmt)
        t1_from_date = t1_to_date - timedelta(days=30)
        t1_from = t1_from_date.strftime(fmt)
        t1_to = t1_to_date.strftime(fmt)

        prev_year = str(int(args["to_year"])-1)
        t2_to_str = f"{prev_year}{current_mmdd}000000"
        t2_to_date = datetime.strptime(t2_to_str, fmt)
        t2_from_date = t2_to_date - timedelta(days=30)
        t2_from = t2_from_date.strftime(fmt)
        t2_to = t2_to_date.strftime(fmt)

    print(f"t1: {t1_from} to {t1_to}")
    print(f"t2: {t2_from} to {t2_to}")

    return (t1_from, t1_to, t2_from, t2_to)


def get_info(algo_args, bbox=None, polygon_geom=None, width=512, height=512, projection=None):
    """Process raster data for deforestation detection"""
    if 'nodata' in algo_args and algo_args['nodata'] is not None:
        algo_args['nodata'] = int(algo_args["nodata"])
    else:
        algo_args['nodata'] = None
    if 'indexes' not in algo_args:
        algo_args['indexes'] = [1]
    if 'merge_method' not in algo_args:
        algo_args['merge_method'] = 'last'
    
    print('\nStarted execution')

    threshold = float(algo_args.get('threshold', 0.3))
    t1_from, t1_to, t2_from, t2_to = build_time_string(algo_args)

    args1 = {**algo_args, 'from_time': t1_from, "to_time": t1_to}
    args2 = {**algo_args, 'from_time': t2_from, "to_time": t2_to}

    ras1 = data.get_raster(args1['dataset_id'], args1['from_time'], args1['to_time'], 
                          bbox, projection, 0, args1['merge_method'], width, height,
                          indexes=args1['indexes'], nodata=args1['nodata'])
    ras2 = data.get_raster(args2['dataset_id'], args2['from_time'], args2['to_time'], 
                          bbox, projection, 0, args2['merge_method'], width, height,
                          indexes=args2['indexes'], nodata=args2['nodata'])

    arr1 = ras1.read(1)
    arr2 = ras2.read(1)

    print(f"arr1 shape: {arr1.shape}, arr2 shape: {arr2.shape}")
    
    if arr1.shape != arr2.shape:
        min_rows = min(arr1.shape[0], arr2.shape[0])
        min_cols = min(arr1.shape[1], arr2.shape[1])
        arr1 = arr1[:min_rows, :min_cols]
        arr2 = arr2[:min_rows, :min_cols]
        print(f"Cropped to common shape: {arr1.shape}")

    diff = arr1 - arr2
    mask = np.logical_and(arr2 > 125, diff < -(threshold * 250))
    
    print(f"Threshold: {threshold * 250}")
    print(f"Detected {np.sum(mask)} deforested pixels")

    # Save TIF files
    arr1_filename = f"current_year_{t1_from}_{t1_to}.tif"
    save_array_as_tiff(arr1, ras1.transform, ras1.crs, arr1_filename, "Current year")

    arr2_filename = f"previous_year_{t2_from}_{t2_to}.tif"
    save_array_as_tiff(arr2, ras1.transform, ras1.crs, arr2_filename, "Previous year")

    output_filename = f"change_detection_{t1_from}_{t2_from}.tif"
    save_diff_tiff(diff, mask, ras1.transform, ras1.crs, output_filename)

    rows, cols = diff.shape

    return {
        'mask': mask,
        'diff': diff,
        'arr1': arr1,
        'arr2': arr2,
        'transform': ras1.transform,
        'crs': ras1.crs,
        'shape': (rows, cols)
    }


def save_single_dataset_tif(dataset_id, from_date, to_date, bbox, projection="EPSG:4326", width=512, height=512):
    """Save a single TIF file for a specific dataset"""
    print(f"\n{'='*60}")
    print(f"Saving TIF for {dataset_id}")
    print(f"{'='*60}")
    
    from_time = from_date.replace("-", "") + "000000"
    to_time = to_date.replace("-", "") + "000000"
    
    print(f"Time range: {from_time} to {to_time}")
    
    args = {
        'dataset_id': dataset_id,
        'from_time': from_time,
        'to_time': to_time,
        'merge_method': 'max',
        'nodata': 255,
        'indexes': [1]
    }
    
    ras = data.get_raster(
        args['dataset_id'], 
        args['from_time'], 
        args['to_time'], 
        bbox, 
        projection, 
        0, 
        args['merge_method'], 
        width, 
        height,
        indexes=args['indexes'], 
        nodata=args['nodata']
    )
    
    arr = ras.read(1)
    print(f"Array shape: {arr.shape}")
    
    output_filename = f"{dataset_id}.tif"
    save_array_as_tiff(arr, ras.transform, ras.crs, output_filename, dataset_id)


if __name__ == "__main__":
    args = {
        "dataset_id": "T3S1P1",
        "filter_nodata": "yes",
        "from_mmdd": "0501",
        "to_mmdd": "0531",
        'merge_method': 'max',
        "threshold": 0.4,
        "from_year": "2024",
        "to_year": "2024",
        'nodata': '255',
        'geojson': """{
        "type": "FeatureCollection",
        "features": [
            {
            "type": "Feature",
            "properties": {},
            "geometry": {
                "coordinates": [
                [
                    [
                    72.42709432225715,
                    23.046288993524698
                    ],
                    [
                    72.42793533605962,
                    23.04369285008039
                    ],
                    [
                    72.42904617845161,
                    23.044110849065902
                    ],
                    [
                    72.42946136546647,
                    23.045314102577805
                    ],
                    [
                    72.42823966574537,
                    23.04656125910556
                    ],
                    [
                    72.42709432225715,
                    23.046288993524698
                    ]
                ]
                ],
                "type": "Polygon"
            }
            }
        ]
        }"""
    }

    bboxes = extract_bbox_from_geojson(args["geojson"])
    
    all_results = {
        "type": "FeatureCollection",
        "features": []
    }

    for idx, (bbox, polygon_geom, feature) in enumerate(bboxes):
        print(f"\nProcessing feature {idx + 1}/{len(bboxes)}")
        print(f"BBox: {bbox}")

        # Get raster data and save current, previous, change detection TIFs
        result_data = get_info(args, bbox=bbox, polygon_geom=polygon_geom,
                              width=512, height=512, projection="EPSG:4326")
        
        mask = result_data['mask']
        diff = result_data['diff']
        arr1 = result_data['arr1']
        arr2 = result_data['arr2']
        transform = result_data['transform']
        crs = result_data['crs']
        shape = result_data['shape']

        # Cluster and get polygons
        clustered_polygons, labeled_array = cluster_connected_pixels_polygons(
            mask, diff, arr1, arr2, transform, crs, polygon_geom
        )
        
        if len(clustered_polygons) > 0:
            # Save cluster polygons as raster TIF
            cluster_poly_tif = f"cluster_polygons_{idx}.tif"
            save_cluster_polygons_tiff(labeled_array, transform, crs, cluster_poly_tif)
            
            # Save cluster center points TIF
            cluster_points_tif = f"cluster_points_{idx}.tif"
            save_cluster_points_tiff(clustered_polygons, transform, crs, shape, cluster_points_tif)
        
        # Add to results for JSON output
        for f in clustered_polygons:
            f['properties']['source_feature_index'] = idx
            all_results['features'].append(f)

    # JSON output to console
    print("\n\nJSON Output (Polygons):")
    print(json.dumps(all_results, indent=2))

    # ============ ADDITIONAL: Save T6S1P3 and T6S1P10 TIF files ============
    bbox = bboxes[0][0]  # Use same bbox
    
    # Save T6S1P3.tif
    save_single_dataset_tif(
        dataset_id="T6S1P3",
        from_date="2023-02-03",
        to_date="2023-05-09",
        bbox=bbox,
        projection="EPSG:4326",
        width=512,
        height=512
    )
    
    # Save T6S1P10.tif
    save_single_dataset_tif(
        dataset_id="T6S1P10",
        from_date="2022-01-05",
        to_date="2025-06-11",
        bbox=bbox,
        projection="EPSG:4326",
        width=512,
        height=512
    )
    
    print("\nâœ“ All processing complete!")
