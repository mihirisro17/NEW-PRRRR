import sys
import os
import concurrent.futures
from datetime import datetime, timedelta

os.environ['GEOENTITY_SERVICE_URL'] = 'http://192.168.2.149:2712/'
sys.path.append('/opt/vedas_env/lib/geoentity_stats_system/pygs_wrapper')

from pygs import PyGS

def doy_to_date(year, doy):
    """
    Convert day-of-year to YYYYMMDD string.
    
    Args:
        year: String year (e.g., "2025")
        doy: String or int day of year (e.g., "129" or 129)
    
    Returns:
        Date string in YYYYMMDD format
    """
    date = datetime(int(year), 1, 1) + timedelta(days=int(doy) - 1)
    return date.strftime("%Y%m%d")

def extract_doys_from_planting_data(planting_data, planting_param_id):
    """
    Extract all unique DOY values from planting data.
    
    Args:
        planting_data: Dictionary containing planting parameter data
        planting_param_id: Parameter ID for planting data
    
    Returns:
        Set of DOY strings found in the data
    """
    doy_set = set()
    
    for geo_id, geo_info in planting_data.items():
        param_values = geo_info.get("param_values", {}).get(planting_param_id, {})
        
        # Iterate through all timestamps
        for timestamp, ts_data in param_values.items():
            value_dict = ts_data.get("value", {})
            
            # Extract all keys except 'nodata'
            for key in value_dict.keys():
                if key != "nodata":
                    doy_set.add(key)
    
    return doy_set

def get_latest_planting_data(pygs_instance, planting_param_id, year):
    """
    Fetch planting data for the specified year to extract DOY values.
    Uses the June 26 date as reference point.
    
    Args:
        pygs_instance: PyGS instance
        planting_param_id: Parameter ID for planting data
        year: String year
    
    Returns:
        Tuple of (planting_data, doy_list)
    """
    # Use June 26 as reference timestamp to get latest planting data
    reference_date = f"{year}0626"
    reference_timestamp = pygs_instance.yyyymmdd_to_timestamp(reference_date)
    
    print(f"Fetching planting data for year {year} to extract DOY values...")
    planting_data = pygs_instance.get_geoentity_source_param_values(
        params=planting_param_id,
        from_time=reference_timestamp,
        print_url=False
    )
    
    # Extract unique DOY values
    doy_set = extract_doys_from_planting_data(planting_data, planting_param_id)
    
    # Sort DOY values numerically
    doy_list = sorted(doy_set, key=lambda x: int(x))
    
    print(f"Extracted DOY values: {doy_list}")
    
    return planting_data, doy_list

def build_dynamic_date_dict(year, doy_list):
    """
    Build date dictionary mapping YYYYMMDD -> DOY.
    
    Args:
        year: String year
        doy_list: List of DOY strings
    
    Returns:
        Dictionary mapping date strings to DOY strings
    """
    date_dict = {}
    for doy in doy_list:
        date_str = doy_to_date(year, doy)
        date_dict[date_str] = doy
    
    print(f"Generated date_dict: {date_dict}")
    return date_dict

def fetch_date_data(pygs_instance, date, planting_param_id, apar_param_id):
    """Helper function to fetch data for a single date (to be used in parallel)."""
    try:
        current_unixtimestamp = pygs_instance.yyyymmdd_to_timestamp(date)
        
        # Fetch APAR
        apar_sum_data = pygs_instance.get_geoentity_source_param_values_otf(
            apar_param_id, [date], print_url=False
        )
        
        # Fetch Planting
        planting_data = pygs_instance.get_geoentity_source_param_values(
            params=planting_param_id,
            from_time=current_unixtimestamp,
            print_url=False
        )
        
        return date, apar_sum_data, planting_data
    except Exception as e:
        print(f"Error fetching data for {date}: {e}")
        return date, {}, {}

def derive_param_values(geoentity_source_id, geoentity_prefix, param_id, *args, **kwargs):
    pygs = PyGS(geoentity_source_id=geoentity_source_id, prefix=geoentity_prefix, **kwargs)
    
    # --- 1. Determine Mode ---
    static_mode = False
    year = args[0]
    if len(args) > 1 and args[1] == "static":
        static_mode = True

    static_ts_str = f"{year}0626"
    static_ts = pygs.yyyymmdd_to_timestamp(static_ts_str)

    Weighted_APARSum_Response = {}
    APAR_param_id = "60002"
    planting_param_id = "119"

    # --- 2. Dynamic Date Mapping (NEW) ---
    # First, fetch planting data to extract available DOY values
    initial_planting_data, doy_list = get_latest_planting_data(pygs, planting_param_id, year)
    
    # Build date dictionary dynamically from extracted DOY values
    date_dict = build_dynamic_date_dict(year, doy_list)
    
    if not date_dict:
        print("Warning: No DOY values found in planting data. Using fallback dates.")
        # Fallback to default dates if no DOY found
        date_dict = {f"{year}0610": "161", f"{year}0626": "177"}

    sum_val = {}

    # --- 3. Parallel Processing ---
    # We use ThreadPoolExecutor to make all API calls at the same time
    # This prevents the Gunicorn timeout by drastically reducing total execution time.
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        # Create a list of tasks
        futures = [
            executor.submit(fetch_date_data, pygs, date, planting_param_id, APAR_param_id) 
            for date in date_dict.keys()
        ]
        
        # Process results as they complete
        for future in concurrent.futures.as_completed(futures):
            date, apar_sum_data, planting_data = future.result()
            sd_value = date_dict[date]  # Get the mapping value (e.g., "161")

            # --- Logic from previous version starts here ---
            CP = {}
            for geo_id, geo_info in planting_data.items():
                if not geo_info.get("param_values") or not geo_info["param_values"].get(planting_param_id):
                    CP[geo_id] = {}
                    continue
                    
                ts_key = list(geo_info["param_values"][planting_param_id].keys())[0]
                values_dict = geo_info["param_values"][planting_param_id][ts_key]["value"]
                vals = {k: v for k, v in values_dict.items() if k != "nodata" and v is not None}
                total = sum(vals.values())
                if total > 0:
                    CP[geo_id] = {k: v / total for k, v in vals.items()}
                else:
                    CP[geo_id] = {k: None for k in vals}

            for geoentity_id, geo_info in apar_sum_data.items():
                param_values = geo_info.get("param_values", {}).get(APAR_param_id)
                if not param_values:
                    continue

                timestamp = list(param_values.keys())[0]
                value = param_values[timestamp]["value"]

                if geoentity_id not in sum_val:
                    sum_val[geoentity_id] = 0

                if value is not None and sd_value in CP.get(geoentity_id, {}):
                    cp_val = CP[geoentity_id][sd_value]
                    if cp_val is not None:
                        sum_val[geoentity_id] += value * cp_val

                # Construction Logic
                if geoentity_id not in Weighted_APARSum_Response:
                    Weighted_APARSum_Response[geoentity_id] = {
                        "name": geo_info["name"],
                        "param_values": {str(param_id): {}}
                    }

                output_ts_key = str(static_ts) if static_mode else str(timestamp)

                Weighted_APARSum_Response[geoentity_id]["param_values"][str(param_id)][output_ts_key] = {
                    "value": sum_val[geoentity_id]
                }

    return Weighted_APARSum_Response

if __name__ == "__main__":
    # Test
    result = derive_param_values(3, 'C91S36', '60006', '2025', 'static')
    print("\nFinal Result Sample:")
    # Print first geoentity as sample
    if result:
        first_key = list(result.keys())[0]
        print(f"{first_key}: {result[first_key]}")
